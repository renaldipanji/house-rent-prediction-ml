# -*- coding: utf-8 -*-
"""House Rent Prediction - Renaldi Panji Wibowo.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/13hvuo6NUM18EqN-Ov9I23zp-MItVnE23

# **Nama : Renaldi Panji Wibowo**

## **Projek Predictive Analysis - House Rent Prediction**

### **Sumber Dataset : https://www.kaggle.com/datasets/iamsouravbanerjee/house-rent-prediction-dataset**

---

# **Data Collection**

## **Mengimport ibrary-library**
"""

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns

"""## **Mengimport Dataset**"""

df_rent = pd.read_csv("House_Rent_Dataset.csv")
df_rent.sample(5)

"""# **Data Understanding & Remove Outlier**

## **Mengecek Jumlah Data dan Fitur**
"""

df_rent.shape

"""## **Mengecek Semua Fitur Dataset**"""

df_rent.info()

"""## **Menghapus Fitur yang tidak diperlukan**"""

# Fitur Point of Contract dan Posted On akan dihapus karena tidak mempengaruhi harga sewa rumah
df_rent = df_rent.drop(['Posted On', 'Point of Contact'], axis = 'columns')

"""## **Univariate Analysis**

### **Fitur Area Type**
"""

df_rent.groupby('Area Type')['Area Type'].agg('count')

# Fitur Area Type hanya terdapat 2 sample Built Area sehingga 2 sample tersebut akan dihapus
df_rent.drop(df_rent.index[df_rent['Area Type'] == 'Built Area'], inplace = True)

df_rent.groupby('Area Type')['Area Type'].agg('count')

"""### **Fitur City**"""

df_rent.groupby('City')['City'].agg('count')

"""### **Fitur FUrnisihing Status**"""

df_rent.groupby('Furnishing Status')['Furnishing Status'].agg('count')

"""### **Fitur Tenant Preferred**"""

df_rent.groupby('Tenant Preferred')['Tenant Preferred'].agg('count')

"""### **Fitur Floor**"""

df_rent.groupby('Floor')['Floor'].agg('count')

"""### **Fitur Area Locality**"""

df_rent.groupby('Area Locality')['Area Locality'].agg('count')

"""### **Menghapus Fitur Floor dan Area Locality**"""

# Fitur Floor dan Area Locality memiliki banyak sekali nilai unique sehingga akan di drop
df_rent = df_rent.drop(['Floor', 'Area Locality'], axis = 'columns')

"""### **Analisis Sebaran Data Pada Fitur Numerik**"""

df_rent.hist(bins=50, figsize=(10,10))
plt.ticklabel_format(useOffset=False, style='plain')
plt.show()

"""## **Multivariate Analysis**

### **Menambah Fitur Baru Price per sqft**
"""

# Menambahkan fitur baru price per sqft
df_rent['Price_per_sqft'] = df_rent['Rent']*1000/df_rent['Size']

df_rent.head()

"""### **Deteksi Outlier pada fitur BHK**"""

# Mendeteksi size per BHK outlier
# 100 sqft untuk 1 BHK itu tidak biasa sehingga anggap saja batasan tresholdnya 300 sqft/bhk

df_rent[(df_rent.Size/df_rent.BHK) < 300].head()

df_rent.shape

"""### **Menghapus Outlier pada BHK**"""

# Menghapus size per BHK outlier
df1_rent = df_rent[~(df_rent.Size/df_rent.BHK < 300)]
df1_rent.head()

df1_rent.shape

"""### **Mendeteksi Outlier pada fitur price per sqft**"""

# Mendeteksi price per sqft outlier
df1_rent.Price_per_sqft.describe().apply(lambda x: format(x, 'f'))

# Menghapus price per sqft outlier dengan mean dan one standard deviation
def remove_pps_outliers(df):
    df_out = pd.DataFrame()
    for key, subdf in df.groupby('City'):
        m = np.mean(subdf.Price_per_sqft)
        st = np.std(subdf.Price_per_sqft)
        reduced_df = subdf[(subdf.Price_per_sqft>(m-st)) & (subdf.Price_per_sqft<=(m+st))]
        df_out = pd.concat([df_out,reduced_df],ignore_index=True)
    return df_out

df2_rent = remove_pps_outliers(df1_rent)
df2_rent.shape

"""### **Mengatasi Outlier pada Bathroom**"""

# Mendeteksi bathroom outlier
# 2 BHK dengan 4 kamar mandi itu tidak biasa jadi anggap saja batasnya kamar mandi tidak boleh melebihi jumlah BHK + 2

df2_rent[df2_rent.Bathroom > df2_rent.BHK + 2]

# Menghapus bathroom outlier
df2_rent = df2_rent[~(df2_rent.Bathroom > df2_rent.BHK + 2)]
df2_rent.head()

df2_rent.shape

"""### **Menghilangkan fitur price per sqft**"""

# Menghilangkan fitur price per sqft karena sudah tidak terpakai
df3_rent = df2_rent.drop(['Price_per_sqft'], axis = 'columns')

"""### **Menganalisis Korelasi Fitur Numerik**"""

# Melihat kolerasi antara fitur numerik dengan fitur target (harga)
plt.figure(figsize=(10, 8))
correlation_matrix = df3_rent.corr().round(2)

# Untuk menge-print nilai di dalam kotak, gunakan parameter anot=True
sns.heatmap(data=correlation_matrix, annot=True, cmap='coolwarm', linewidths=0.5, )
plt.title("Correlation Matrix untuk Fitur Numerik ", size=20)

"""### **Analisis Fitur Kategorikal**

**Fitur Area Type**
"""

# Melihat kolerasi antara fitur kategorik dengan fitur target (harga)
cat_features = df2_rent.select_dtypes(include='object').columns.to_list()

for col in cat_features:
  sns.catplot(x=col, y="Rent", kind="bar", dodge=False, height = 4, aspect = 3,  data=df2_rent, palette="Set3")
  plt.title("Rata-rata 'Rent' Relatif terhadap - {}".format(col))

"""## **Data Preparation**

### **One Hot Encoding untuk Fitur Kategorikal**
"""

# df3_rent = pd.get_dummies(data =  df3_rent, columns = ['Area Type'])
# df3_rent = pd.get_dummies(data =  df3_rent, columns = ['City'])
# df3_rent = pd.get_dummies(data =  df3_rent, columns = ['Furnishing Status'])
df3_rent = pd.get_dummies(data =  df3_rent, columns = ['Tenant Preferred'])

df3_rent.head()

"""## **Train Test Split**"""

from sklearn.model_selection import train_test_split

X = df3_rent.drop(["Rent"],axis =1)
y = df3_rent["Rent"]
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.1, random_state=123)

print(f'Total # of sample in whole dataset: {len(X)}')
print(f'Total # of sample in train dataset: {len(X_train)}')
print(f'Total # of sample in test dataset: {len(X_test)}')

"""## **Normalisasi Data Numerik**"""

from sklearn.preprocessing import StandardScaler

# Normalisasi data train
numerical_features = ['BHK', 'Size', 'Bathroom']
scaler = StandardScaler()
scaler.fit(X_train[numerical_features])
X_train[numerical_features] = scaler.transform(X_train.loc[:, numerical_features])
X_train[numerical_features].head()

# Normalisasi data test
X_test.loc[:, numerical_features] = scaler.transform(X_test[numerical_features])

"""## **Modelling**

### **Grid Search**
"""

from sklearn.neighbors import KNeighborsRegressor
from sklearn.ensemble import RandomForestRegressor
from sklearn.ensemble import AdaBoostRegressor

from sklearn.model_selection import GridSearchCV
from sklearn.model_selection import ShuffleSplit

def grid_search_model(X,y):
    algos = {
        'knn': {
            'model': KNeighborsRegressor(),
            'params': {
                'n_neighbors': [3,4,5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15],
            }
        },
        'boosting': {
            'model': AdaBoostRegressor(),
            'params': {
                'learning_rate' : [0.1, 0.05, 0.01, 0.05, 0.001],
                'n_estimators': [25, 50, 75, 100],
                'random_state': [11, 33, 55, 77]
            }
        },
        'random_forest': {
            'model': RandomForestRegressor(),
            'params': {
                'n_estimators': [25, 50, 75, 100],
                'max_depth' : [8, 16, 32, 64],
                'random_state': [11, 33, 55, 77],
            }
        }

    }

    scores = []
    cv = ShuffleSplit(n_splits=5, test_size=0.1, random_state=123)
    for algo_name, config in algos.items():
        gs =  GridSearchCV(config['model'], config['params'], cv=cv, return_train_score=False)
        gs.fit(X,y)
        scores.append({
            'model': algo_name,
            'best_score': gs.best_score_,
            'best_params': gs.best_params_
        })

    return pd.DataFrame(scores,columns=['model','best_score','best_params'])

grid_search_model(X,y)

"""## **Model with best parameter**"""

acc = pd.DataFrame(index=['accuracy'])

from sklearn.metrics import mean_squared_error

"""### **K-NN**"""

knn = KNeighborsRegressor(n_neighbors = 3)
knn.fit(X_train, y_train)
acc.loc['accuracy', 'knn'] = knn.score(X_test,y_test)
knn.score(X_test,y_test)

"""### **Random Forest**"""

rf = RandomForestRegressor(n_estimators = 25, max_depth = 8, random_state = 77)
rf.fit(X_train, y_train)
acc.loc['accuracy', 'rf'] = rf.score(X_test,y_test)
rf.score(X_test,y_test)

"""### **Adaboost**"""

boosting = AdaBoostRegressor(n_estimators = 25, learning_rate = 0.001, random_state = 33)
boosting.fit(X_train, y_train)
acc.loc['accuracy', 'boosting'] = boosting.score(X_test,y_test)
boosting.score(X_test,y_test)

"""## **Evaluation**"""

acc

# Mean squared error dari model
mse = pd.DataFrame(columns=['train', 'test'], index=['KNN','RF','Boosting'])

model_dict = {'KNN': knn, 'RF': rf, 'Boosting': boosting}

for name, model in model_dict.items():
    mse.loc[name, 'train'] = mean_squared_error(y_true=y_train, y_pred=model.predict(X_train))/1e3
    mse.loc[name, 'test'] = mean_squared_error(y_true=y_test, y_pred=model.predict(X_test))/1e3

mse

fig, ax = plt.subplots()
mse.sort_values(by='test', ascending=False).plot(kind='barh', ax=ax, zorder=3)
ax.grid(zorder=0)

prediksi = X_test.iloc[5:10].copy()
pred_dict = {'y_true':y_test[5:10]}
for name, model in model_dict.items():
    pred_dict['prediksi_'+name] = model.predict(prediksi).round(1)

pd.DataFrame(pred_dict)